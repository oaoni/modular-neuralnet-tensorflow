{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gene expression data\n",
    "data = pd.read_csv(\"../../data/gene_expression_clinical.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003.13</th>\n",
       "      <th>ENSG00000000005.5</th>\n",
       "      <th>ENSG00000000419.11</th>\n",
       "      <th>ENSG00000000457.12</th>\n",
       "      <th>ENSG00000000460.15</th>\n",
       "      <th>ENSG00000000938.11</th>\n",
       "      <th>ENSG00000000971.14</th>\n",
       "      <th>ENSG00000001036.12</th>\n",
       "      <th>ENSG00000001084.9</th>\n",
       "      <th>ENSG00000001167.13</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSGR0000264510.4</th>\n",
       "      <th>ENSGR0000264819.4</th>\n",
       "      <th>ENSGR0000265658.4</th>\n",
       "      <th>ENSGR0000270726.4</th>\n",
       "      <th>ENSGR0000275287.3</th>\n",
       "      <th>ENSGR0000276543.3</th>\n",
       "      <th>ENSGR0000277120.3</th>\n",
       "      <th>ENSGR0000280767.1</th>\n",
       "      <th>ENSGR0000281849.1</th>\n",
       "      <th>sample_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts</th>\n",
       "      <td>4219</td>\n",
       "      <td>4</td>\n",
       "      <td>1070</td>\n",
       "      <td>565</td>\n",
       "      <td>133</td>\n",
       "      <td>1493</td>\n",
       "      <td>54514</td>\n",
       "      <td>2894</td>\n",
       "      <td>6042</td>\n",
       "      <td>867</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts</th>\n",
       "      <td>3428</td>\n",
       "      <td>5</td>\n",
       "      <td>821</td>\n",
       "      <td>502</td>\n",
       "      <td>537</td>\n",
       "      <td>278</td>\n",
       "      <td>103347</td>\n",
       "      <td>2307</td>\n",
       "      <td>4815</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts</th>\n",
       "      <td>5284</td>\n",
       "      <td>7</td>\n",
       "      <td>1403</td>\n",
       "      <td>704</td>\n",
       "      <td>119</td>\n",
       "      <td>629</td>\n",
       "      <td>98287</td>\n",
       "      <td>3840</td>\n",
       "      <td>7077</td>\n",
       "      <td>673</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts</th>\n",
       "      <td>3236</td>\n",
       "      <td>0</td>\n",
       "      <td>697</td>\n",
       "      <td>643</td>\n",
       "      <td>56</td>\n",
       "      <td>200</td>\n",
       "      <td>39678</td>\n",
       "      <td>1685</td>\n",
       "      <td>5872</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts</th>\n",
       "      <td>3051</td>\n",
       "      <td>11</td>\n",
       "      <td>984</td>\n",
       "      <td>353</td>\n",
       "      <td>70</td>\n",
       "      <td>387</td>\n",
       "      <td>36361</td>\n",
       "      <td>2870</td>\n",
       "      <td>4070</td>\n",
       "      <td>586</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ENSG00000000003.13  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                4219   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                3428   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                5284   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                3236   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                3051   \n",
       "\n",
       "                                                    ENSG00000000005.5  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  4   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  5   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  7   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 11   \n",
       "\n",
       "                                                    ENSG00000000419.11  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                1070   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 821   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                1403   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                 697   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 984   \n",
       "\n",
       "                                                    ENSG00000000457.12  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                 565   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 502   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                 704   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                 643   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 353   \n",
       "\n",
       "                                                    ENSG00000000460.15  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                 133   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 537   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                 119   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  56   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  70   \n",
       "\n",
       "                                                    ENSG00000000938.11  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                1493   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 278   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                 629   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                 200   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 387   \n",
       "\n",
       "                                                    ENSG00000000971.14  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts               54514   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts              103347   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts               98287   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts               39678   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts               36361   \n",
       "\n",
       "                                                    ENSG00000001036.12  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                2894   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                2307   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                3840   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                1685   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                2870   \n",
       "\n",
       "                                                    ENSG00000001084.9  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts               6042   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts               4815   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts               7077   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts               5872   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts               4070   \n",
       "\n",
       "                                                    ENSG00000001167.13  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                 867   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 486   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                 673   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                 477   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 586   \n",
       "\n",
       "                                                       ...       \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts     ...        \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts     ...        \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts     ...        \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts     ...        \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts     ...        \n",
       "\n",
       "                                                    ENSGR0000264510.4  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000264819.4  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000265658.4  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000270726.4  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000275287.3  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000276543.3  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000277120.3  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000280767.1  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000281849.1  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    sample_type  \n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts            0  \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts            0  \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts            0  \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts            0  \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts            0  \n",
       "\n",
       "[5 rows x 60484 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove non-relavant columns\n",
    "data.drop(data.columns[[60483,60484,60485,60486,60488,60489,60490,60491,60492,60493,60494,60495]],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principle component analysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((data.shape[0],2))\n",
    "y[:,0] = data['sample_type'].values\n",
    "y[:,1] = [1 if x==0 else 0 for x in y[:,0]]\n",
    "Y = y\n",
    "#Zero in the first field is benign, and zero in the second field is malignant\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=15) #Make a PCA object with n = 15 PCs\n",
    "pca.fit(data.drop(['sample_type'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = pca.transform(data.drop(['sample_type'],axis=1))\n",
    "pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the data set\n",
    "X,Y = shuffle(pc,Y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dataset into train and test set\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,Y,test_size=0.30, random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779, 15)\n",
      "(779, 2)\n",
      "(335, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_optimizers = ['gd']\n",
    "allowed_activations = ['sigmoid', 'tanh', 'softmax', 'relu', 'linear']\n",
    "allowed_losses = ['rmse', 'cross_entropy']\n",
    "\n",
    "class ModularNeuralNet:\n",
    "    \"\"\"\n",
    "    Modular deep artificial neural network implemented in a sklearn style\n",
    "    \"\"\"\n",
    "    \n",
    "    #Class assertions\n",
    "    def assertions(self):\n",
    "        global allowed_optimizers, allowed_activations, allowed_losses\n",
    "        assert self.loss in allowed_losses, 'Invalid loss function given'\n",
    "        assert self.optimizer in allowed_optimizers, 'Invalid optimizer given'\n",
    "        assert all(x in allowed_activations for x in self.activations), 'Invalid activation function used'\n",
    "        assert self.epochs > 0, 'Number of epochs must be greater than 0'\n",
    "    \n",
    "    def __init__(self, input_dim = 15,n_class=2,hidden_nodes=[16,16,16,16],lr=0.1,epochs=10,\n",
    "                activations=['relu','relu','relu','sigmoid'],loss='cross_entropy',\n",
    "                optimizer='gd',batch_size=100, print_step=1,graph=False,save_model=False):\n",
    "        self.n_class = n_class\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.hidden_layers = len(self.hidden_nodes)\n",
    "        self.input_dim = input_dim       \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.activations = activations\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.print_step = print_step\n",
    "        self.graph = graph\n",
    "        self.save_model = save_model\n",
    "        self.assertions()\n",
    "\n",
    "        self.model_path = os.path.join(os.getcwd(),\"model\\\\\")\n",
    "        self.graph_path = os.path.join(os.getcwd(),\"graph\\\\\")\n",
    "        self.cost_history = []\n",
    "        self.mse_history = []\n",
    "        self.accuracy_history = []\n",
    "        self.weights_dim = [self.input_dim] + self.hidden_nodes\n",
    "        \n",
    "    #Fit takes training input data and trains a neural network with user specified infrastructure\n",
    "    def fit(self, train_x, train_y):\n",
    "        '''\n",
    "        :param x: m x p dataframe\n",
    "        :return: trained weights and bias for the sdae       \n",
    "        '''\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        #Generate tensorflow variables for the weights and biases\n",
    "        weights = self.weight()\n",
    "        biases = self.bias()\n",
    "        \n",
    "        x = tf.placeholder(dtype=tf.float32,shape=[None, self.input_dim])\n",
    "        W = tf.Variable(tf.zeros([self.input_dim, self.n_class]))\n",
    "        b = tf.Variable(tf.zeros([self.n_class]))\n",
    "        y_ = tf.placeholder(dtype=tf.float32,shape=[None,self.n_class])\n",
    "        y = tf.placeholder(dtype=tf.float32,shape=[None,self.n_class])\n",
    "        \n",
    "        #Initialize variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        #Initialize saver class\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        #Call the defined model\n",
    "        y = self.mlp(x,weights,biases)\n",
    "\n",
    "        #Define the cost function and optimizer\n",
    "        cost_function = self.cost(self.loss, y, y_)\n",
    "        training_step = self.optimizers(self.lr,cost_function)\n",
    "        \n",
    "        #Define equations for correct prediction and accuracy\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        \n",
    "        #Initialize tensorflow session\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            sess.run(training_step, feed_dict={x:train_x, y_:train_y})\n",
    "            \n",
    "            #Current training cost\n",
    "            cost = sess.run(cost_function, feed_dict={x:train_x,y_:train_y})\n",
    "            self.cost_history.append(cost)\n",
    "            \n",
    "            #Current test set MSE, move to transform method\n",
    "            #pred_y = sess.run(y,feed_dict={x:test_x})\n",
    "            #mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "            #mse_ = sess.run(mse)\n",
    "            #self.mse_history.append(mse_)\n",
    "            \n",
    "            #Current training accuracy\n",
    "            accuracy_ = (sess.run(accuracy, feed_dict={x:train_x,y_:train_y}))\n",
    "            self.accuracy_history.append(accuracy_)\n",
    "            \n",
    "            print('epoch : ', epoch, ' - ', 'cost: ', cost, ' - ', 'accuracy: ', accuracy_)\n",
    "            \n",
    "        #Save tensorflow graph based on class specification \n",
    "        if self.graph:\n",
    "            File_Writer = tf.summary.FileWriter(self.graph_path, sess.graph)\n",
    "            print('Tensorboard graph saved to: ', self.graph_path)\n",
    "        \n",
    "        if self.save_model:\n",
    "            save_path = saver.save(sess,self.model_path)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "        #Plot cost and training accuracy on class specification\n",
    "        \n",
    "        return sess.run(cost_function, feed_dict={x: train_x, y_:train_y})\n",
    "        \n",
    "    #Implements the desired cost function\n",
    "    def cost(self,loss, y, y_):\n",
    "        if loss == 'rmse':\n",
    "            return tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(y_, y))))\n",
    "        elif loss == 'cross_entropy':\n",
    "            #Removed tf.reduce_mean\n",
    "            return tf.losses.softmax_cross_entropy(logits=y,onehot_labels=y_)\n",
    "    \n",
    "    #Implements the desired cost function\n",
    "    def optimizers(self, lr, loss):\n",
    "        if self.optimizer == 'gd':\n",
    "            return tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "        \n",
    "        elif self.optimizer == 'adam':\n",
    "            return tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    \n",
    "    #Implements the desired activation function\n",
    "    def activate(self, linear, name):\n",
    "        if name == 'sigmoid':\n",
    "            return tf.nn.sigmoid(linear, name='layer')\n",
    "        elif name == 'softmax':\n",
    "            return tf.nn.softmax(linear, name='layer')\n",
    "        elif name == 'linear':\n",
    "            return linear\n",
    "        elif name == 'tanh':\n",
    "            return tf.nn.tanh(linear, name='layer')\n",
    "        elif name == 'relu':\n",
    "            return tf.nn.relu(linear, name='layer')\n",
    "        \n",
    "    def weight(self):\n",
    "        weights = {'out':tf.Variable(tf.truncated_normal([self.weights_dim[-1],self.n_class]),\n",
    "                                     dtype=tf.float32)}\n",
    "        for i in range(self.hidden_layers):\n",
    "            var = 'h'+str(i)\n",
    "            weights[var] = tf.Variable(tf.truncated_normal([self.weights_dim[i],self.weights_dim[i+1]]),\n",
    "                                      dtype=tf.float32)\n",
    "        return weights\n",
    "    \n",
    "    def bias(self):\n",
    "        biases = {'out':tf.Variable(tf.truncated_normal([self.n_class]),\n",
    "                                   dtype=tf.float32)}\n",
    "        for i in range(self.hidden_layers):\n",
    "            var = var = 'b'+str(i)\n",
    "            biases[var] = tf.Variable(tf.truncated_normal([self.hidden_nodes[i]]),\n",
    "                                     dtype=tf.float32)\n",
    "        return biases\n",
    "    \n",
    "    #Define the multiple layer perceptron model\n",
    "    def mlp(self, x, weights, biases):\n",
    "\n",
    "        layer = x\n",
    "        #Hidden Layers\n",
    "        for i in range(self.hidden_layers):\n",
    "            layer = tf.add(tf.matmul(layer,weights['h'+str(i)]),biases['b'+str(i)])\n",
    "            layer = self.activate(layer,self.activations[i])\n",
    "            \n",
    "        #Output Layer\n",
    "        out_layer = tf.add(tf.matmul(layer, weights['out']), biases['out'])\n",
    "        \n",
    "        return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate class\n",
    "model = ModularNeuralNet(epochs=100,hidden_nodes=[4,8,12,16],graph=False,save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -  cost:  0.87869  -  accuracy:  0.554557\n",
      "epoch :  1  -  cost:  0.709604  -  accuracy:  0.617458\n",
      "epoch :  2  -  cost:  0.619431  -  accuracy:  0.617458\n",
      "epoch :  3  -  cost:  0.570254  -  accuracy:  0.617458\n",
      "epoch :  4  -  cost:  0.542394  -  accuracy:  0.617458\n",
      "epoch :  5  -  cost:  0.525846  -  accuracy:  0.617458\n",
      "epoch :  6  -  cost:  0.515484  -  accuracy:  0.810013\n",
      "epoch :  7  -  cost:  0.508546  -  accuracy:  0.810013\n",
      "epoch :  8  -  cost:  0.503739  -  accuracy:  0.810013\n",
      "epoch :  9  -  cost:  0.500088  -  accuracy:  0.810013\n",
      "epoch :  10  -  cost:  0.49722  -  accuracy:  0.81258\n",
      "epoch :  11  -  cost:  0.494814  -  accuracy:  0.81258\n",
      "epoch :  12  -  cost:  0.492659  -  accuracy:  0.81258\n",
      "epoch :  13  -  cost:  0.49075  -  accuracy:  0.81258\n",
      "epoch :  14  -  cost:  0.488979  -  accuracy:  0.81258\n",
      "epoch :  15  -  cost:  0.487307  -  accuracy:  0.81258\n",
      "epoch :  16  -  cost:  0.485485  -  accuracy:  0.81258\n",
      "epoch :  17  -  cost:  0.48395  -  accuracy:  0.81258\n",
      "epoch :  18  -  cost:  0.482466  -  accuracy:  0.81258\n",
      "epoch :  19  -  cost:  0.481026  -  accuracy:  0.81258\n",
      "epoch :  20  -  cost:  0.479626  -  accuracy:  0.81258\n",
      "epoch :  21  -  cost:  0.478264  -  accuracy:  0.81258\n",
      "epoch :  22  -  cost:  0.476936  -  accuracy:  0.81258\n",
      "epoch :  23  -  cost:  0.475642  -  accuracy:  0.81258\n",
      "epoch :  24  -  cost:  0.47438  -  accuracy:  0.81258\n",
      "epoch :  25  -  cost:  0.473148  -  accuracy:  0.81258\n",
      "epoch :  26  -  cost:  0.471849  -  accuracy:  0.81258\n",
      "epoch :  27  -  cost:  0.470673  -  accuracy:  0.81258\n",
      "epoch :  28  -  cost:  0.469526  -  accuracy:  0.81258\n",
      "epoch :  29  -  cost:  0.468406  -  accuracy:  0.81258\n",
      "epoch :  30  -  cost:  0.467313  -  accuracy:  0.81258\n",
      "epoch :  31  -  cost:  0.466246  -  accuracy:  0.81258\n",
      "epoch :  32  -  cost:  0.464982  -  accuracy:  0.81258\n",
      "epoch :  33  -  cost:  0.463958  -  accuracy:  0.81258\n",
      "epoch :  34  -  cost:  0.462959  -  accuracy:  0.81258\n",
      "epoch :  35  -  cost:  0.461983  -  accuracy:  0.81258\n",
      "epoch :  36  -  cost:  0.461031  -  accuracy:  0.81258\n",
      "epoch :  37  -  cost:  0.460101  -  accuracy:  0.81258\n",
      "epoch :  38  -  cost:  0.459017  -  accuracy:  0.81258\n",
      "epoch :  39  -  cost:  0.457948  -  accuracy:  0.81258\n",
      "epoch :  40  -  cost:  0.456892  -  accuracy:  0.81258\n",
      "epoch :  41  -  cost:  0.455905  -  accuracy:  0.81258\n",
      "epoch :  42  -  cost:  0.455058  -  accuracy:  0.81258\n",
      "epoch :  43  -  cost:  0.454772  -  accuracy:  0.81258\n",
      "epoch :  44  -  cost:  0.453891  -  accuracy:  0.81258\n",
      "epoch :  45  -  cost:  0.453103  -  accuracy:  0.81258\n",
      "epoch :  46  -  cost:  0.452332  -  accuracy:  0.81258\n",
      "epoch :  47  -  cost:  0.451579  -  accuracy:  0.81258\n",
      "epoch :  48  -  cost:  0.450842  -  accuracy:  0.81258\n",
      "epoch :  49  -  cost:  0.450122  -  accuracy:  0.81258\n",
      "epoch :  50  -  cost:  0.449418  -  accuracy:  0.81258\n",
      "epoch :  51  -  cost:  0.448729  -  accuracy:  0.81258\n",
      "epoch :  52  -  cost:  0.448056  -  accuracy:  0.81258\n",
      "epoch :  53  -  cost:  0.448035  -  accuracy:  0.81258\n",
      "epoch :  54  -  cost:  0.447394  -  accuracy:  0.81258\n",
      "epoch :  55  -  cost:  0.446444  -  accuracy:  0.81258\n",
      "epoch :  56  -  cost:  0.446258  -  accuracy:  0.81258\n",
      "epoch :  57  -  cost:  0.44566  -  accuracy:  0.81258\n",
      "epoch :  58  -  cost:  0.444972  -  accuracy:  0.81258\n",
      "epoch :  59  -  cost:  0.444285  -  accuracy:  0.81258\n",
      "epoch :  60  -  cost:  0.44372  -  accuracy:  0.81258\n",
      "epoch :  61  -  cost:  0.443167  -  accuracy:  0.81258\n",
      "epoch :  62  -  cost:  0.442525  -  accuracy:  0.81258\n",
      "epoch :  63  -  cost:  0.441992  -  accuracy:  0.81258\n",
      "epoch :  64  -  cost:  0.441368  -  accuracy:  0.81258\n",
      "epoch :  65  -  cost:  0.440855  -  accuracy:  0.81258\n",
      "epoch :  66  -  cost:  0.44026  -  accuracy:  0.81258\n",
      "epoch :  67  -  cost:  0.439766  -  accuracy:  0.81258\n",
      "epoch :  68  -  cost:  0.439187  -  accuracy:  0.81258\n",
      "epoch :  69  -  cost:  0.438867  -  accuracy:  0.81258\n",
      "epoch :  70  -  cost:  0.438399  -  accuracy:  0.81258\n",
      "epoch :  71  -  cost:  0.437749  -  accuracy:  0.81258\n",
      "epoch :  72  -  cost:  0.437188  -  accuracy:  0.81258\n",
      "epoch :  73  -  cost:  0.436743  -  accuracy:  0.81258\n",
      "epoch :  74  -  cost:  0.436306  -  accuracy:  0.81258\n",
      "epoch :  75  -  cost:  0.435877  -  accuracy:  0.81258\n",
      "epoch :  76  -  cost:  0.435456  -  accuracy:  0.81258\n",
      "epoch :  77  -  cost:  0.435043  -  accuracy:  0.81258\n",
      "epoch :  78  -  cost:  0.434638  -  accuracy:  0.81258\n",
      "epoch :  79  -  cost:  0.43424  -  accuracy:  0.81258\n",
      "epoch :  80  -  cost:  0.433849  -  accuracy:  0.81258\n",
      "epoch :  81  -  cost:  0.433466  -  accuracy:  0.81258\n",
      "epoch :  82  -  cost:  0.433088  -  accuracy:  0.81258\n",
      "epoch :  83  -  cost:  0.432674  -  accuracy:  0.831836\n",
      "epoch :  84  -  cost:  0.431936  -  accuracy:  0.831836\n",
      "epoch :  85  -  cost:  0.431168  -  accuracy:  0.831836\n",
      "epoch :  86  -  cost:  0.430483  -  accuracy:  0.831836\n",
      "epoch :  87  -  cost:  0.429817  -  accuracy:  0.831836\n",
      "epoch :  88  -  cost:  0.429168  -  accuracy:  0.831836\n",
      "epoch :  89  -  cost:  0.428534  -  accuracy:  0.831836\n",
      "epoch :  90  -  cost:  0.427914  -  accuracy:  0.831836\n",
      "epoch :  91  -  cost:  0.427308  -  accuracy:  0.831836\n",
      "epoch :  92  -  cost:  0.426713  -  accuracy:  0.831836\n",
      "epoch :  93  -  cost:  0.426073  -  accuracy:  0.831836\n",
      "epoch :  94  -  cost:  0.425502  -  accuracy:  0.831836\n",
      "epoch :  95  -  cost:  0.4245  -  accuracy:  0.831836\n",
      "epoch :  96  -  cost:  0.423953  -  accuracy:  0.831836\n",
      "epoch :  97  -  cost:  0.423415  -  accuracy:  0.831836\n",
      "epoch :  98  -  cost:  0.422889  -  accuracy:  0.831836\n",
      "epoch :  99  -  cost:  0.422371  -  accuracy:  0.831836\n",
      "Model saved in file: C:\\Users\\oaoni\\OneDrive - McMaster University\\CSE\\Term2\\CAS771\\BigDataProject\\modular-neuralnet-tensorflow\\ModularNeuralNet\\model\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42237139"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y,1).eval(session=sess),tf.argmax(y,1)),\n",
    "                             tf.float32)).eval(session=sess))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
