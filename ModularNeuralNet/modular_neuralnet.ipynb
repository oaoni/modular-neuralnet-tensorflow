{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gene expression data\n",
    "data = pd.read_csv(\"../../data/gene_expression_clinical.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003.13</th>\n",
       "      <th>ENSG00000000005.5</th>\n",
       "      <th>ENSG00000000419.11</th>\n",
       "      <th>ENSG00000000457.12</th>\n",
       "      <th>ENSG00000000460.15</th>\n",
       "      <th>ENSG00000000938.11</th>\n",
       "      <th>ENSG00000000971.14</th>\n",
       "      <th>ENSG00000001036.12</th>\n",
       "      <th>ENSG00000001084.9</th>\n",
       "      <th>ENSG00000001167.13</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSGR0000264510.4</th>\n",
       "      <th>ENSGR0000264819.4</th>\n",
       "      <th>ENSGR0000265658.4</th>\n",
       "      <th>ENSGR0000270726.4</th>\n",
       "      <th>ENSGR0000275287.3</th>\n",
       "      <th>ENSGR0000276543.3</th>\n",
       "      <th>ENSGR0000277120.3</th>\n",
       "      <th>ENSGR0000280767.1</th>\n",
       "      <th>ENSGR0000281849.1</th>\n",
       "      <th>sample_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts</th>\n",
       "      <td>4219</td>\n",
       "      <td>4</td>\n",
       "      <td>1070</td>\n",
       "      <td>565</td>\n",
       "      <td>133</td>\n",
       "      <td>1493</td>\n",
       "      <td>54514</td>\n",
       "      <td>2894</td>\n",
       "      <td>6042</td>\n",
       "      <td>867</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts</th>\n",
       "      <td>3428</td>\n",
       "      <td>5</td>\n",
       "      <td>821</td>\n",
       "      <td>502</td>\n",
       "      <td>537</td>\n",
       "      <td>278</td>\n",
       "      <td>103347</td>\n",
       "      <td>2307</td>\n",
       "      <td>4815</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts</th>\n",
       "      <td>5284</td>\n",
       "      <td>7</td>\n",
       "      <td>1403</td>\n",
       "      <td>704</td>\n",
       "      <td>119</td>\n",
       "      <td>629</td>\n",
       "      <td>98287</td>\n",
       "      <td>3840</td>\n",
       "      <td>7077</td>\n",
       "      <td>673</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts</th>\n",
       "      <td>3236</td>\n",
       "      <td>0</td>\n",
       "      <td>697</td>\n",
       "      <td>643</td>\n",
       "      <td>56</td>\n",
       "      <td>200</td>\n",
       "      <td>39678</td>\n",
       "      <td>1685</td>\n",
       "      <td>5872</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts</th>\n",
       "      <td>3051</td>\n",
       "      <td>11</td>\n",
       "      <td>984</td>\n",
       "      <td>353</td>\n",
       "      <td>70</td>\n",
       "      <td>387</td>\n",
       "      <td>36361</td>\n",
       "      <td>2870</td>\n",
       "      <td>4070</td>\n",
       "      <td>586</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ENSG00000000003.13  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                4219   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                3428   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                5284   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                3236   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                3051   \n",
       "\n",
       "                                                    ENSG00000000005.5  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  4   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  5   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  7   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 11   \n",
       "\n",
       "                                                    ENSG00000000419.11  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                1070   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 821   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                1403   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                 697   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 984   \n",
       "\n",
       "                                                    ENSG00000000457.12  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                 565   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 502   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                 704   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                 643   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 353   \n",
       "\n",
       "                                                    ENSG00000000460.15  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                 133   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 537   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                 119   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  56   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  70   \n",
       "\n",
       "                                                    ENSG00000000938.11  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                1493   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 278   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                 629   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                 200   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 387   \n",
       "\n",
       "                                                    ENSG00000000971.14  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts               54514   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts              103347   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts               98287   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts               39678   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts               36361   \n",
       "\n",
       "                                                    ENSG00000001036.12  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                2894   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                2307   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                3840   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                1685   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                2870   \n",
       "\n",
       "                                                    ENSG00000001084.9  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts               6042   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts               4815   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts               7077   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts               5872   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts               4070   \n",
       "\n",
       "                                                    ENSG00000001167.13  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                 867   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                 486   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                 673   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                 477   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                 586   \n",
       "\n",
       "                                                       ...       \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts     ...        \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts     ...        \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts     ...        \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts     ...        \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts     ...        \n",
       "\n",
       "                                                    ENSGR0000264510.4  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000264819.4  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000265658.4  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000270726.4  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000275287.3  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000276543.3  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000277120.3  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000280767.1  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    ENSGR0000281849.1  \\\n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts                  0   \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts                  0   \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts                  0   \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts                  0   \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts                  0   \n",
       "\n",
       "                                                    sample_type  \n",
       "X15a44c9d.7c84.4170.96a1.358dd796aa65.htseq.counts            0  \n",
       "X160aee04.df36.4e94.90c5.b01b2991ba48.htseq.counts            0  \n",
       "X1d86dc66.1a62.4cbc.9973.ae63ab754d6a.htseq.counts            0  \n",
       "X2b8bf629.3c22.4dcb.a9a5.ec01c5099167.htseq.counts            0  \n",
       "X2cc2e3ce.68cd.4690.9fff.5ecf86c2f57a.htseq.counts            0  \n",
       "\n",
       "[5 rows x 60484 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove non-relavant columns\n",
    "data.drop(data.columns[[60483,60484,60485,60486,60488,60489,60490,60491,60492,60493,60494,60495]],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principle component analysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((data.shape[0],2))\n",
    "y[:,0] = data['sample_type'].values\n",
    "y[:,1] = [1 if x==0 else 0 for x in y[:,0]]\n",
    "Y = y\n",
    "#Zero in the first field is benign, and zero in the second field is malignant\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=15) #Make a PCA object with n = 15 PCs\n",
    "pca.fit(data.drop(['sample_type'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = pca.transform(data.drop(['sample_type'],axis=1))\n",
    "pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the data set\n",
    "X,Y = shuffle(pc,Y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dataset into train and test set\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,Y,test_size=0.30, random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779, 15)\n",
      "(779, 2)\n",
      "(335, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_optimizers = ['gd']\n",
    "allowed_activations = ['sigmoid', 'tanh', 'softmax', 'relu', 'linear']\n",
    "allowed_losses = ['rmse', 'cross_entropy']\n",
    "\n",
    "class ModularNeuralNet:\n",
    "    \"\"\"\n",
    "    Modular deep artificial neural network implemented in a sklearn style\n",
    "    \"\"\"\n",
    "    \n",
    "    #Class assertions\n",
    "    def assertions(self):\n",
    "        global allowed_optimizers, allowed_activations, allowed_losses\n",
    "        assert self.loss in allowed_losses, 'Invalid loss function given'\n",
    "        assert self.optimizer in allowed_optimizers, 'Invalid optimizer given'\n",
    "        assert all(x in allowed_activations for x in self.activations), 'Invalid activation function used'\n",
    "        assert self.epochs > 0, 'Number of epochs must be greater than 0'\n",
    "    \n",
    "    def __init__(self, input_dim = 15,n_class=2,hidden_nodes=[16,16,16,16],lr=0.1,epochs=10,\n",
    "                activations=['relu','relu','relu','sigmoid'],loss='cross_entropy',\n",
    "                optimizer='gd',batch_size=100, print_step=1,graph=False,save_model=False):\n",
    "        self.n_class = n_class\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.hidden_layers = len(self.hidden_nodes)\n",
    "        self.input_dim = input_dim       \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.activations = activations\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.print_step = print_step\n",
    "        self.graph = graph\n",
    "        self.save_model = save_model\n",
    "        self.assertions()\n",
    "        \n",
    "        self.model_path = os.path.join(os.getcwd(),\"model\\\\\")\n",
    "        self.cost_history = []\n",
    "        self.mse_history = []\n",
    "        self.accuracy_history = np.empty(shape=[1],dtype=float)\n",
    "        self.weights_dim = [self.input_dim] + self.hidden_nodes\n",
    "        \n",
    "    #Fit takes training input data and trains a neural network with user specified infrastructure\n",
    "    def fit(self, train_x, train_y):\n",
    "        '''\n",
    "        :param x: m x p dataframe\n",
    "        :return: trained weights and bias for the sdae       \n",
    "        '''\n",
    "        \n",
    "        #Generate tensorflow variables for the weights and biases\n",
    "        weights = self.weight()\n",
    "        biases = self.bias()\n",
    "        \n",
    "        x = tf.placeholder(dtype=tf.float32,shape=[None, self.input_dim])\n",
    "        W = tf.Variable(tf.zeros([self.input_dim, self.n_class]))\n",
    "        b = tf.Variable(tf.zeros([self.n_class]))\n",
    "        y_ = tf.placeholder(dtype=tf.float32,shape=[None,self.n_class])\n",
    "        y = tf.placeholder(dtype=tf.float32,shape=[None,self.n_class])\n",
    "        \n",
    "        #Initialize variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        #Initialize saver class\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        #Call the defined model\n",
    "        y = self.mlp(x,weights,biases)\n",
    "\n",
    "        #Define the cost function and optimizer\n",
    "        cost_function = self.cost(self.loss, y, y_)\n",
    "        training_step = self.optimizers(self.lr,cost_function)\n",
    "        \n",
    "        #Initialize tensorflow session\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            sess.run(training_step, feed_dict={x:train_x, y_:train_y})\n",
    "            #Current training cost\n",
    "            cost = sess.run(cost_function, feed_dict={x:train_x,y_:train_y})\n",
    "            self.cost_history.append(cost)\n",
    "            #Test set MSE\n",
    "            #pred_y = sess.run(y,feed_dict={x:test_x})\n",
    "           # mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "           # mse_ = sess.run(mse)\n",
    "           # mse_history.append(mse_)\n",
    "            ##Add accuracy history##\n",
    "            print('epoch : ', epoch, ' - ', 'cost: ', cost)\n",
    "        \n",
    "        return sess.run(cost_function, feed_dict={x: train_x, y_:train_y})\n",
    "        \n",
    "        \n",
    "    #Implements the desired cost function\n",
    "    def cost(self,loss, y, y_):\n",
    "        if loss == 'rmse':\n",
    "            return tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(y_, y))))\n",
    "        elif loss == 'cross_entropy':\n",
    "            #Removed tf.reduce_mean\n",
    "            return tf.losses.softmax_cross_entropy(logits=y,onehot_labels=y_)\n",
    "    \n",
    "    #Implements the desired cost function\n",
    "    def optimizers(self, lr, loss):\n",
    "        if self.optimizer == 'gd':\n",
    "            return tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "        \n",
    "        elif self.optimizer == 'adam':\n",
    "            return tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    \n",
    "    #Implements the desired activation function\n",
    "    def activate(self, linear, name):\n",
    "        if name == 'sigmoid':\n",
    "            return tf.nn.sigmoid(linear, name='layer')\n",
    "        elif name == 'softmax':\n",
    "            return tf.nn.softmax(linear, name='layer')\n",
    "        elif name == 'linear':\n",
    "            return linear\n",
    "        elif name == 'tanh':\n",
    "            return tf.nn.tanh(linear, name='layer')\n",
    "        elif name == 'relu':\n",
    "            return tf.nn.relu(linear, name='layer')\n",
    "        \n",
    "    def weight(self):\n",
    "        weights = {'out':tf.Variable(tf.truncated_normal([self.weights_dim[-1],self.n_class]),\n",
    "                                     dtype=tf.float32)}\n",
    "        for i in range(self.hidden_layers):\n",
    "            var = 'h'+str(i)\n",
    "            weights[var] = tf.Variable(tf.truncated_normal([self.weights_dim[i],self.weights_dim[i+1]]),\n",
    "                                      dtype=tf.float32)\n",
    "        return weights\n",
    "    \n",
    "    def bias(self):\n",
    "        biases = {'out':tf.Variable(tf.truncated_normal([self.n_class]),\n",
    "                                   dtype=tf.float32)}\n",
    "        for i in range(self.hidden_layers):\n",
    "            var = var = 'b'+str(i)\n",
    "            biases[var] = tf.Variable(tf.truncated_normal([self.hidden_nodes[i]]),\n",
    "                                     dtype=tf.float32)\n",
    "        return biases\n",
    "    \n",
    "    #Define the multiple layer perceptron model\n",
    "    def mlp(self, x, weights, biases):\n",
    "\n",
    "        layer = x\n",
    "        #Hidden Layers\n",
    "        for i in range(self.hidden_layers):\n",
    "            layer = tf.add(tf.matmul(layer,weights['h'+str(i)]),biases['b'+str(i)])\n",
    "            layer = self.activate(layer,self.activations[i])\n",
    "            \n",
    "        #Output Layer\n",
    "        out_layer = tf.add(tf.matmul(layer, weights['out']), biases['out'])\n",
    "        \n",
    "        return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate class\n",
    "model = ModularNeuralNet(epochs=200,hidden_nodes=[4,8,12,16],graph=True,save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -  cost:  1.31639\n",
      "epoch :  1  -  cost:  0.951491\n",
      "epoch :  2  -  cost:  0.761017\n",
      "epoch :  3  -  cost:  0.664189\n",
      "epoch :  4  -  cost:  0.615641\n",
      "epoch :  5  -  cost:  0.585224\n",
      "epoch :  6  -  cost:  0.569463\n",
      "epoch :  7  -  cost:  0.567379\n",
      "epoch :  8  -  cost:  0.561877\n",
      "epoch :  9  -  cost:  0.557706\n",
      "epoch :  10  -  cost:  0.553518\n",
      "epoch :  11  -  cost:  0.550464\n",
      "epoch :  12  -  cost:  0.547702\n",
      "epoch :  13  -  cost:  0.544501\n",
      "epoch :  14  -  cost:  0.54482\n",
      "epoch :  15  -  cost:  0.541845\n",
      "epoch :  16  -  cost:  0.540509\n",
      "epoch :  17  -  cost:  0.539085\n",
      "epoch :  18  -  cost:  0.539901\n",
      "epoch :  19  -  cost:  0.539355\n",
      "epoch :  20  -  cost:  0.53925\n",
      "epoch :  21  -  cost:  0.537284\n",
      "epoch :  22  -  cost:  0.536138\n",
      "epoch :  23  -  cost:  0.535015\n",
      "epoch :  24  -  cost:  0.532447\n",
      "epoch :  25  -  cost:  0.531383\n",
      "epoch :  26  -  cost:  0.529564\n",
      "epoch :  27  -  cost:  0.527776\n",
      "epoch :  28  -  cost:  0.526214\n",
      "epoch :  29  -  cost:  0.525201\n",
      "epoch :  30  -  cost:  0.523375\n",
      "epoch :  31  -  cost:  0.522137\n",
      "epoch :  32  -  cost:  0.521218\n",
      "epoch :  33  -  cost:  0.520293\n",
      "epoch :  34  -  cost:  0.519366\n",
      "epoch :  35  -  cost:  0.518352\n",
      "epoch :  36  -  cost:  0.517232\n",
      "epoch :  37  -  cost:  0.516388\n",
      "epoch :  38  -  cost:  0.515534\n",
      "epoch :  39  -  cost:  0.562569\n",
      "epoch :  40  -  cost:  0.555585\n",
      "epoch :  41  -  cost:  0.551093\n",
      "epoch :  42  -  cost:  0.548195\n",
      "epoch :  43  -  cost:  0.546259\n",
      "epoch :  44  -  cost:  0.544878\n",
      "epoch :  45  -  cost:  0.543807\n",
      "epoch :  46  -  cost:  0.542905\n",
      "epoch :  47  -  cost:  0.542095\n",
      "epoch :  48  -  cost:  0.541335\n",
      "epoch :  49  -  cost:  0.540602\n",
      "epoch :  50  -  cost:  0.539885\n",
      "epoch :  51  -  cost:  0.539178\n",
      "epoch :  52  -  cost:  0.538479\n",
      "epoch :  53  -  cost:  0.537785\n",
      "epoch :  54  -  cost:  0.537096\n",
      "epoch :  55  -  cost:  0.536412\n",
      "epoch :  56  -  cost:  0.535732\n",
      "epoch :  57  -  cost:  0.535056\n",
      "epoch :  58  -  cost:  0.534385\n",
      "epoch :  59  -  cost:  0.533717\n",
      "epoch :  60  -  cost:  0.533054\n",
      "epoch :  61  -  cost:  0.532394\n",
      "epoch :  62  -  cost:  0.531739\n",
      "epoch :  63  -  cost:  0.531088\n",
      "epoch :  64  -  cost:  0.530441\n",
      "epoch :  65  -  cost:  0.529799\n",
      "epoch :  66  -  cost:  0.52916\n",
      "epoch :  67  -  cost:  0.528525\n",
      "epoch :  68  -  cost:  0.527894\n",
      "epoch :  69  -  cost:  0.527268\n",
      "epoch :  70  -  cost:  0.526646\n",
      "epoch :  71  -  cost:  0.526028\n",
      "epoch :  72  -  cost:  0.523921\n",
      "epoch :  73  -  cost:  0.523331\n",
      "epoch :  74  -  cost:  0.522746\n",
      "epoch :  75  -  cost:  0.522165\n",
      "epoch :  76  -  cost:  0.521587\n",
      "epoch :  77  -  cost:  0.521013\n",
      "epoch :  78  -  cost:  0.520443\n",
      "epoch :  79  -  cost:  0.519879\n",
      "epoch :  80  -  cost:  0.519316\n",
      "epoch :  81  -  cost:  0.518759\n",
      "epoch :  82  -  cost:  0.518205\n",
      "epoch :  83  -  cost:  0.517655\n",
      "epoch :  84  -  cost:  0.51711\n",
      "epoch :  85  -  cost:  0.516568\n",
      "epoch :  86  -  cost:  0.51603\n",
      "epoch :  87  -  cost:  0.515496\n",
      "epoch :  88  -  cost:  0.514966\n",
      "epoch :  89  -  cost:  0.51444\n",
      "epoch :  90  -  cost:  0.513918\n",
      "epoch :  91  -  cost:  0.513399\n",
      "epoch :  92  -  cost:  0.512885\n",
      "epoch :  93  -  cost:  0.512374\n",
      "epoch :  94  -  cost:  0.511867\n",
      "epoch :  95  -  cost:  0.511364\n",
      "epoch :  96  -  cost:  0.510865\n",
      "epoch :  97  -  cost:  0.510369\n",
      "epoch :  98  -  cost:  0.509877\n",
      "epoch :  99  -  cost:  0.50939\n",
      "epoch :  100  -  cost:  0.508906\n",
      "epoch :  101  -  cost:  0.508425\n",
      "epoch :  102  -  cost:  0.507949\n",
      "epoch :  103  -  cost:  0.507476\n",
      "epoch :  104  -  cost:  0.507006\n",
      "epoch :  105  -  cost:  0.50654\n",
      "epoch :  106  -  cost:  0.506079\n",
      "epoch :  107  -  cost:  0.50562\n",
      "epoch :  108  -  cost:  0.505166\n",
      "epoch :  109  -  cost:  0.504714\n",
      "epoch :  110  -  cost:  0.504267\n",
      "epoch :  111  -  cost:  0.503823\n",
      "epoch :  112  -  cost:  0.503383\n",
      "epoch :  113  -  cost:  0.502945\n",
      "epoch :  114  -  cost:  0.502512\n",
      "epoch :  115  -  cost:  0.502082\n",
      "epoch :  116  -  cost:  0.501656\n",
      "epoch :  117  -  cost:  0.501232\n",
      "epoch :  118  -  cost:  0.500813\n",
      "epoch :  119  -  cost:  0.500397\n",
      "epoch :  120  -  cost:  0.499984\n",
      "epoch :  121  -  cost:  0.499574\n",
      "epoch :  122  -  cost:  0.499168\n",
      "epoch :  123  -  cost:  0.498765\n",
      "epoch :  124  -  cost:  0.498365\n",
      "epoch :  125  -  cost:  0.497969\n",
      "epoch :  126  -  cost:  0.497577\n",
      "epoch :  127  -  cost:  0.497186\n",
      "epoch :  128  -  cost:  0.4968\n",
      "epoch :  129  -  cost:  0.496416\n",
      "epoch :  130  -  cost:  0.496037\n",
      "epoch :  131  -  cost:  0.49566\n",
      "epoch :  132  -  cost:  0.495285\n",
      "epoch :  133  -  cost:  0.494915\n",
      "epoch :  134  -  cost:  0.494547\n",
      "epoch :  135  -  cost:  0.494182\n",
      "epoch :  136  -  cost:  0.49382\n",
      "epoch :  137  -  cost:  0.493461\n",
      "epoch :  138  -  cost:  0.493105\n",
      "epoch :  139  -  cost:  0.492752\n",
      "epoch :  140  -  cost:  0.492403\n",
      "epoch :  141  -  cost:  0.492056\n",
      "epoch :  142  -  cost:  0.491711\n",
      "epoch :  143  -  cost:  0.49137\n",
      "epoch :  144  -  cost:  0.491032\n",
      "epoch :  145  -  cost:  0.490696\n",
      "epoch :  146  -  cost:  0.490364\n",
      "epoch :  147  -  cost:  0.490033\n",
      "epoch :  148  -  cost:  0.489706\n",
      "epoch :  149  -  cost:  0.489382\n",
      "epoch :  150  -  cost:  0.48906\n",
      "epoch :  151  -  cost:  0.48874\n",
      "epoch :  152  -  cost:  0.488423\n",
      "epoch :  153  -  cost:  0.48811\n",
      "epoch :  154  -  cost:  0.487798\n",
      "epoch :  155  -  cost:  0.487489\n",
      "epoch :  156  -  cost:  0.487183\n",
      "epoch :  157  -  cost:  0.486879\n",
      "epoch :  158  -  cost:  0.486578\n",
      "epoch :  159  -  cost:  0.486279\n",
      "epoch :  160  -  cost:  0.485982\n",
      "epoch :  161  -  cost:  0.485689\n",
      "epoch :  162  -  cost:  0.485397\n",
      "epoch :  163  -  cost:  0.485108\n",
      "epoch :  164  -  cost:  0.484822\n",
      "epoch :  165  -  cost:  0.484537\n",
      "epoch :  166  -  cost:  0.484255\n",
      "epoch :  167  -  cost:  0.483975\n",
      "epoch :  168  -  cost:  0.483697\n",
      "epoch :  169  -  cost:  0.483423\n",
      "epoch :  170  -  cost:  0.48315\n",
      "epoch :  171  -  cost:  0.482879\n",
      "epoch :  172  -  cost:  0.48261\n",
      "epoch :  173  -  cost:  0.482343\n",
      "epoch :  174  -  cost:  0.482079\n",
      "epoch :  175  -  cost:  0.481817\n",
      "epoch :  176  -  cost:  0.481556\n",
      "epoch :  177  -  cost:  0.481298\n",
      "epoch :  178  -  cost:  0.481042\n",
      "epoch :  179  -  cost:  0.480788\n",
      "epoch :  180  -  cost:  0.480536\n",
      "epoch :  181  -  cost:  0.480286\n",
      "epoch :  182  -  cost:  0.480038\n",
      "epoch :  183  -  cost:  0.479792\n",
      "epoch :  184  -  cost:  0.479548\n",
      "epoch :  185  -  cost:  0.479305\n",
      "epoch :  186  -  cost:  0.479064\n",
      "epoch :  187  -  cost:  0.478826\n",
      "epoch :  188  -  cost:  0.478589\n",
      "epoch :  189  -  cost:  0.478354\n",
      "epoch :  190  -  cost:  0.478121\n",
      "epoch :  191  -  cost:  0.477889\n",
      "epoch :  192  -  cost:  0.47766\n",
      "epoch :  193  -  cost:  0.477432\n",
      "epoch :  194  -  cost:  0.477206\n",
      "epoch :  195  -  cost:  0.476981\n",
      "epoch :  196  -  cost:  0.476759\n",
      "epoch :  197  -  cost:  0.476537\n",
      "epoch :  198  -  cost:  0.476318\n",
      "epoch :  199  -  cost:  0.4761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47609997"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cross_entropy'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'h'+str(i):2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out': <tf.Variable 'Variable:0' shape=(16, 2) dtype=float32_ref>}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "j = 0\n",
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h0': <tf.Variable 'Variable_7:0' shape=(15, 4) dtype=float32_ref>,\n",
       " 'h1': <tf.Variable 'Variable_8:0' shape=(4, 8) dtype=float32_ref>,\n",
       " 'h2': <tf.Variable 'Variable_9:0' shape=(8, 12) dtype=float32_ref>,\n",
       " 'h3': <tf.Variable 'Variable_10:0' shape=(12, 16) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_6:0' shape=(16, 2) dtype=float32_ref>}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {'out':tf.Variable(tf.truncated_normal([model.weights_dim[-1],model.n_class]))}\n",
    "for i in range(model.hidden_layers):\n",
    "    var = 'h'+str(i)\n",
    "    weights[var] = tf.Variable(tf.truncated_normal([model.weights_dim[i],model.weights_dim[i+1]]))\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': <tf.Variable 'Variable_1:0' shape=(15, 4) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable:0' shape=(16, 2) dtype=float32_ref>}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 1]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = np.append(apple,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 1, 2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 1, 2, 2])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(apple,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-a11c6b5cab3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "np.random.rand(5).append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables and parameters to work with tensors\n",
    "learning_rate = 0.1\n",
    "training_epochs = 10\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "n_dim = 15\n",
    "n_class = 2\n",
    "model_path = os.path.join(os.getcwd(),\"model\\\\\")\n",
    "\n",
    "n_hidden_1 = 16\n",
    "n_hidden_2 = 16\n",
    "n_hidden_3 = 16\n",
    "n_hidden_4 = 16\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32,[None,n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, weights,biases):\n",
    "\n",
    "    layer = x\n",
    "\n",
    "    #Hidden Layers\n",
    "    for i in range(model.hidden_layers):\n",
    "        layer = tf.add(tf.matmul(layer,weights['h'+str(i)]),biases['b'+str(i)])\n",
    "        layer = model.activate(layer,model.activations[i])\n",
    "            \n",
    "    #Output Layer\n",
    "    out_layer = tf.add(tf.matmul(layer, weights['out']), biases['out'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h0':tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h1':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_4,n_class]))\n",
    "}\n",
    "biases = {\n",
    "    'b0':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_39:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = mlp(x, weights, biases)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_180:0' shape=(15, 16) dtype=float32_ref>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights['h0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-187-b34461a6889d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'layer' is not defined"
     ]
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gd'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
